{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuoZhuyin/zhuyinasia/blob/main/DeepLearning/modeltest1_TEAM_855_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4131b7ca",
      "metadata": {
        "id": "4131b7ca"
      },
      "source": [
        "## 隨機挑選訓練集進行測試判斷模型準確率"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bda2861",
      "metadata": {
        "id": "0bda2861"
      },
      "outputs": [],
      "source": [
        "import PIL\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c1065ec",
      "metadata": {
        "id": "1c1065ec"
      },
      "outputs": [],
      "source": [
        "class_to_index={'banana': 0, 'bareland': 1, 'building': 2, 'carrot': 3, 'corn': 4,\n",
        " 'dragonfruit': 5, 'garlic': 6, 'guava': 7, 'mountain': 8, 'peanut': 9, 'pineapple': 10,\n",
        " 'pumpkin': 11, 'rice': 12, 'sky': 13, 'soybean': 14, 'sugarcane': 15, 'tomato': 16}\n",
        "index_to_class = {v: k for k, v in class_to_index.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2e8f7d0",
      "metadata": {
        "id": "a2e8f7d0"
      },
      "outputs": [],
      "source": [
        "classes=['banana', 'bareland', 'carrot', 'corn', 'dragonfruit', 'garlic', 'guava', 'peanut', 'pineapple', 'pumpkin', 'rice', 'soybean', 'sugarcane', 'tomato', 'building', 'mountain', 'sky']\n",
        "num_classes = len(classes)\n",
        "print(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf7087de",
      "metadata": {
        "id": "bf7087de"
      },
      "outputs": [],
      "source": [
        "folders=['banana', 'bareland', 'carrot', 'corn', 'dragonfruit', 'garlic', 'guava', 'peanut', 'pineapple', 'pumpkin', 'rice', 'soybean', 'sugarcane', 'tomato']\n",
        "num_folders = len(folders)\n",
        "print(num_folders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a7b764b",
      "metadata": {
        "id": "2a7b764b"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "#model = models.inception_v3(pretrained=False)\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=False)\n",
        "model.aux_logits = False\n",
        "model.fc =  nn.Linear(model.fc.in_features, num_classes)\n",
        "model = nn.DataParallel(model) #cuda設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2578fe9d",
      "metadata": {
        "id": "2578fe9d"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('../model/InV3_TEAM_855_5.0.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ecc4da9",
      "metadata": {
        "id": "5ecc4da9"
      },
      "source": [
        "輸入的模型參數"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb495039",
      "metadata": {
        "id": "fb495039"
      },
      "outputs": [],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e18fc52",
      "metadata": {
        "id": "0e18fc52"
      },
      "outputs": [],
      "source": [
        "model = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af725f2d",
      "metadata": {
        "id": "af725f2d"
      },
      "outputs": [],
      "source": [
        "from PIL import Image \n",
        "fname = subpath=os.path.join(\"banana\", \"160107-3-0035.JPG\")\n",
        "im_banana = Image.open(fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c8c986f",
      "metadata": {
        "id": "9c8c986f"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "display(im_banana) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b7acca3",
      "metadata": {
        "id": "5b7acca3"
      },
      "outputs": [],
      "source": [
        "width, height = im_banana.size   # Get dimensions\n",
        "print(width, height)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8125089e",
      "metadata": {
        "id": "8125089e"
      },
      "outputs": [],
      "source": [
        "new_width = 512\n",
        "new_height = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d4c4569",
      "metadata": {
        "id": "8d4c4569"
      },
      "outputs": [],
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),\n",
        "    transforms.ToTensor(), # ToTensor : [0, 255] -> [0, 1]\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e93c01e5",
      "metadata": {
        "id": "e93c01e5"
      },
      "source": [
        "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b3ec9f9",
      "metadata": {
        "id": "4b3ec9f9"
      },
      "outputs": [],
      "source": [
        "class MyImgDataset(Dataset):\n",
        "    \"\"\"FarmLand single dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, image, label=None, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            image (Image): singe image.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.image = image\n",
        "        self.label = label\n",
        "        self.transform = transform\n",
        "        self.boxes=list()\n",
        "\n",
        "        count = 0\n",
        "        width, height = image.size   # Get dimensions\n",
        "        new_width = 512\n",
        "        new_height = 512\n",
        "        stride = 32\n",
        "        for startx in range(width//8, width*7//8-new_width, stride):\n",
        "          for starty in range(height//2, height-new_height, stride):\n",
        "              left = startx\n",
        "              top = starty\n",
        "              right = startx + new_width\n",
        "              bottom = starty + new_height\n",
        "              self.boxes.append((left, top, right, bottom))\n",
        "    def __len__(self):\n",
        "        return len(self.boxes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "                # Crop the sub image\n",
        "        left, top, right, bottom = self.boxes[idx]\n",
        "        im2 = im.crop((left, top, right, bottom))\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(im2)\n",
        "        else:\n",
        "            sample = im2\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57a48b40",
      "metadata": {
        "id": "57a48b40"
      },
      "outputs": [],
      "source": [
        "mydataset = MyImgDataset(im_banana, class_to_index['banana'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb577d1e",
      "metadata": {
        "id": "eb577d1e"
      },
      "outputs": [],
      "source": [
        "testset = MyImgDataset(im_banana, class_to_index['banana'], test_transform)\n",
        "test_dataloader = DataLoader(testset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c851f9e5",
      "metadata": {
        "id": "c851f9e5"
      },
      "outputs": [],
      "source": [
        "def accumulate_blocks(stats, arr):\n",
        "    for index in arr:\n",
        "      if index == 2 or index == 8 or index == 13:\n",
        "           continue\n",
        "      stats[index] +=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c443a85b",
      "metadata": {
        "id": "c443a85b"
      },
      "outputs": [],
      "source": [
        "classes=['banana', 'bareland', 'carrot', 'corn', 'dragonfruit', 'garlic', 'guava', 'peanut', 'pineapple', 'pumpkin', 'rice', 'soybean', 'sugarcane', 'tomato', 'building', 'mountain', 'sky']\n",
        "num_classes = len(classes)\n",
        "print(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21fd6ec6",
      "metadata": {
        "id": "21fd6ec6"
      },
      "outputs": [],
      "source": [
        "def judge_class(im, label, model, transform, batch_size):\n",
        "    testset = MyImgDataset(im, label, transform)\n",
        "    test_dataloader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
        "    stats = [0 for i in range(17)] \n",
        "    for images in test_dataloader:\n",
        "        images = images.cuda()\n",
        "        outputs = model(images)\n",
        "        _, dets = torch.max(outputs, 1)\n",
        "        accumulate_blocks(stats, dets)\n",
        "    return stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa765827",
      "metadata": {
        "id": "aa765827"
      },
      "outputs": [],
      "source": [
        "folders=['banana', 'bareland', 'carrot', 'corn', 'dragonfruit', 'garlic', 'guava', 'peanut', 'pineapple', 'pumpkin', 'rice', 'soybean', 'sugarcane', 'tomato']\n",
        "print(len(folders))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d190354",
      "metadata": {
        "id": "5d190354",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from PIL import Image \n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "batch_size = 64 #GPU調整batch\n",
        "for f in folders:\n",
        "    subpath=os.path.join(f, \"*\")\n",
        "    files = glob.glob(subpath)\n",
        "    print(f\"Categroy:{f}\")\n",
        "    for fname in files:\n",
        "        im = Image.open(fname)\n",
        "        label = class_to_index[f]\n",
        "        stats=judge_class(im, label, model,  test_transform, batch_size)\n",
        "        curclass=index_to_class[np.argmax(stats)]\n",
        "        if curclass == f:\n",
        "            correct_pred[curclass] += 1\n",
        "            print(f\"Right:{fname}->{curclass}:{stats}\")\n",
        "        else:\n",
        "            print(f\"Wrong:{fname}->{curclass}:{stats}\")\n",
        "        total_pred[curclass] += 1\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    if classname not in folders:\n",
        "        continue\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "modeltest1_TEAM_855_3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
